{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urlparse, unquote\n",
    "import json\n",
    "import csv\n",
    "# os.environ['PATH'] += r\"E:\\Installers\\chromedriver_win32\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cào"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIST VIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_list_view_elise(url, domain):\n",
    "    product_info_list = []\n",
    "    html_content = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_content, \"html5lib\")\n",
    "    all_product_list = soup.find('div', class_='list')\n",
    "    all_items = all_product_list.find_all('div', class_='c-item')\n",
    "    for item in all_items:\n",
    "        product_id = None\n",
    "        \n",
    "        product_sku = None\n",
    "        \n",
    "        general_id = f'{domain}_{product_id}'\n",
    "        \n",
    "        product_name = item.find('h3', class_='c-name').text.strip()\n",
    "        \n",
    "        product_price = item.find('div', class_='price').text.strip()\n",
    "        \n",
    "        product_url = item.find('a')['href']\n",
    "        \n",
    "        colors = []\n",
    "        color_elements = item.find_all('p', class_='c-box_color')\n",
    "        for ce in color_elements:\n",
    "            ce_a_tag = ce.find('a', class_='c-color')\n",
    "            color = ce_a_tag.get('title')\n",
    "            colors.append(color)\n",
    "            \n",
    "        # Product images\n",
    "        images = item.find_all('img')\n",
    "        img_dict = {}\n",
    "\n",
    "        image_order = 1\n",
    "        for img in images:   \n",
    "            img_name = img['alt']\n",
    "            img_order_name = f'{image_order:03d}_{img_name}'\n",
    "            \n",
    "            img_src = img['src']\n",
    "            img_dict[img_order_name] = img_src\n",
    "                    \n",
    "            image_order += 1\n",
    "        \n",
    "        product_info = {\n",
    "        'general_id': general_id,\n",
    "        'product_id': product_id,\n",
    "        'sku': product_sku,\n",
    "        'url': product_url,\n",
    "        'product_name': product_name,\n",
    "        'price': product_price,\n",
    "        'image_list': img_dict\n",
    "        }    \n",
    "        \n",
    "        # print(json.dumps(product_info, indent=4))    \n",
    "        product_info_list.append(product_info)\n",
    "        \n",
    "    product_info_list_df = pd.DataFrame(product_info_list)\n",
    "    return product_info_list_df\n",
    "\n",
    "crawl_list_view_elise(url='https://sixdo.vn/san-pham/page-34', domain='sixdo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETAIL VIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://sixdo.vn/white-polka-dot-midi-chiffon-dress-1-pd3962'\n",
    "html_content = requests.get(url).text\n",
    "soup = BeautifulSoup(html_content, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68220611201DI1845\n",
      "White Polka Dot Midi Chiffon Dress\n",
      "4905164\n",
      "['Trắng']\n"
     ]
    }
   ],
   "source": [
    "def crawl_detail_view_elise(soup, domain):\n",
    "    \n",
    "    product_id = soup.find('p', class_='c-code').text.replace('MSP:', '').strip()\n",
    "    print(product_id)\n",
    "    \n",
    "    general_id = f'{domain}_{product_id}'\n",
    "    \n",
    "    sku = None\n",
    "    \n",
    "    product_name = soup.find('h2', class_='c-title_module').text.strip()\n",
    "    print(product_name)\n",
    "    \n",
    "    price = soup.find('span', id='price-no-discount')['data-price']\n",
    "    print(price)\n",
    "    \n",
    "    colors = []\n",
    "    color_elements = soup.find_all('p', class_='color c-show_color--name')\n",
    "    for ce in color_elements:\n",
    "        color = ce.find('span').text.strip()\n",
    "        colors.append(color)\n",
    "    print(colors)\n",
    "\n",
    "crawl_detail_view_elise(soup, domain='sixdo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
